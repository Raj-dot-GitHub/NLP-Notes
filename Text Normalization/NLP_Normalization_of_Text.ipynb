{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Normalization_of_Text.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNLTrNjGeV59Dn9vRvcp2/P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raj-dot-GitHub/NLP-Notes/blob/main/Text%20Normalization/NLP_Normalization_of_Text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf-q6lLUKQ3v"
      },
      "source": [
        "## **Text Normalization**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok_mxrDHLfV7"
      },
      "source": [
        "### **What is Text Normalization?**\n",
        "> **Text Normalization** is a process of reducing a word to its root form."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ydc7dEXuKxya"
      },
      "source": [
        "### We have two ways of Text Normalization:\n",
        "1. Stemming.\n",
        "2. Lemmatization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3BNkS3-LLI_"
      },
      "source": [
        "### **What are Stemming and Lemmatization?**\n",
        "> **Stemming** and **Lemmatization** is simply normalization of words, which means reducing a word to its root form."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PW3gzcfJNEV5"
      },
      "source": [
        "### **What is Stemming?**\n",
        "> \n",
        "\n",
        "*   Stemming is a text normalization technique that cuts off the end or beginning of a word by taking into account a list of common prefixes or suffixes that could be found in that word\n",
        "*   It is a rudimentary rule-based process of stripping the suffixes (“ing”, “ly”, “es”, “s” etc) from a word\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElOLma0DNbrz"
      },
      "source": [
        "### **What is Lemmatization?**\n",
        "> Lemmatization, on the other hand, is an organized & step-by-step procedure of obtaining the root form of the word. It makes use of vocabulary (dictionary importance of words) and morphological analysis (word structure and grammar relations)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2cN3uyKON2n"
      },
      "source": [
        "### **Benefits of Text Normalization:**\n",
        "> Let’s consider the following two sentences:\n",
        "\n",
        "* He was driving\n",
        "* He went for a drive\n",
        "\n",
        "We can easily state that both the sentences are conveying the same meaning, that is, driving activity in the past. A machine will treat both sentences differently. Thus, to make the text understandable for the machine, we need to perform stemming or lemmatization.\n",
        "\n",
        "Another benefit of text normalization is that it reduces the number of unique words in the text data. This helps in bringing down the training time of the machine learning model (and don’t we all want that?)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1TPUdV_OkBF"
      },
      "source": [
        "### **Stemming vs Lemmatization. Which one should I prefer?**\n",
        "> **Stemming** algorithm works by cutting the suffix or prefix from the word. **Lemmatization** is a more powerful operation as it takes into consideration the morphological analysis of the word.\n",
        "\n",
        "Lemmatization returns the **lemma**, which is the root word of all its inflection forms.\n",
        "\n",
        "We can say that stemming is a quick and dirty method of chopping off words to its root form while on the other hand, lemmatization is an intelligent operation that uses dictionaries which are created by in-depth linguistic knowledge. **Hence, Lemmatization helps in forming better features.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2u26WDhPRBz"
      },
      "source": [
        "## **Text Normalization using NLTK**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztyBNzVAPZ-n"
      },
      "source": [
        "### **Stemming**\n",
        "\n",
        "For stemming we use PorterStemmer() method in NLTK."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKzmIczXJ6ic"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq_web2YQMQD",
        "outputId": "4c6aae2d-7c0d-4aa2-f37b-ef0357cf4e2e"
      },
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "print(len(stop_words))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "179\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0nyhmhzQfeY"
      },
      "source": [
        "text = \"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \n",
        "fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \n",
        "indeed the vaguest idea where the wood and river in question were.\"\"\"\n",
        "\n",
        "# Performing word tokenization.\n",
        "word_tokens = word_tokenize(text)      "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNmep-gtQtu8",
        "outputId": "fbd8f384-61f2-44a3-bb98-08be1179ca01"
      },
      "source": [
        "# Stopwords removal.\n",
        "filtered_sentence = []\n",
        "\n",
        "for word in word_tokens:\n",
        "  if word not in stop_words:\n",
        "    filtered_sentence.append(word)\n",
        "\n",
        "print(filtered_sentence)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['He', 'determined', 'drop', 'litigation', 'monastry', ',', 'relinguish', 'claims', 'wood-cuting', 'fishery', 'rihgts', '.', 'He', 'ready', 'becuase', 'rights', 'become', 'much', 'less', 'valuable', ',', 'indeed', 'vaguest', 'idea', 'wood', 'river', 'question', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKrRSfmcRunp",
        "outputId": "4ab19d6a-e3de-4c9a-d108-f6944e374b3f"
      },
      "source": [
        "# Appling Stemming.\n",
        "stem_words = []\n",
        "ps = PorterStemmer()\n",
        "for word in filtered_sentence:\n",
        "  root_word = ps.stem(word)\n",
        "  stem_words.append(root_word)\n",
        "\n",
        "print(filtered_sentence)\n",
        "print(stem_words)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['He', 'determined', 'drop', 'litigation', 'monastry', ',', 'relinguish', 'claims', 'wood-cuting', 'fishery', 'rihgts', '.', 'He', 'ready', 'becuase', 'rights', 'become', 'much', 'less', 'valuable', ',', 'indeed', 'vaguest', 'idea', 'wood', 'river', 'question', '.']\n",
            "['He', 'determin', 'drop', 'litig', 'monastri', ',', 'relinguish', 'claim', 'wood-cut', 'fisheri', 'rihgt', '.', 'He', 'readi', 'becuas', 'right', 'becom', 'much', 'less', 'valuabl', ',', 'inde', 'vaguest', 'idea', 'wood', 'river', 'question', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuBzkMs3ShX3"
      },
      "source": [
        "### **Lemmatization.**\n",
        ">For Lemmatization we will use WordNetLemmatizer method from NLTK."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeUxHNb7STXy"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqIBENq3TAPO"
      },
      "source": [
        "text2 = \"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \n",
        "fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \n",
        "indeed the vaguest idea where the wood and river in question were.\"\"\"\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "word_tokens = word_tokenize(text2)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKdjHlU-TVEb",
        "outputId": "eb7fe7ae-d4d8-462e-bcae-315dbc0618a1"
      },
      "source": [
        "# Stopwords removal.\n",
        "\n",
        "filtered_sentence = []\n",
        "\n",
        "for word in word_tokens:\n",
        "  if word not in stop_words:\n",
        "    filtered_sentence.append(word)\n",
        "\n",
        "print(filtered_sentence)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['He', 'determined', 'drop', 'litigation', 'monastry', ',', 'relinguish', 'claims', 'wood-cuting', 'fishery', 'rihgts', '.', 'He', 'ready', 'becuase', 'rights', 'become', 'much', 'less', 'valuable', ',', 'indeed', 'vaguest', 'idea', 'wood', 'river', 'question', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJaaYvC8TpBp",
        "outputId": "4dd4a8fc-8869-4f23-e00e-94cad79e43f9"
      },
      "source": [
        "lemma_words = []\n",
        "\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "for word in filtered_sentence:\n",
        "  word1 = wordnet_lemmatizer.lemmatize(word, pos = \"n\")\n",
        "  word2 = wordnet_lemmatizer.lemmatize(word1, pos = \"v\")\n",
        "  word3 = wordnet_lemmatizer.lemmatize(word2, pos = (\"a\"))\n",
        "  lemma_words.append(word3)\n",
        "\n",
        "print(filtered_sentence)\n",
        "print(lemma_words)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['He', 'determined', 'drop', 'litigation', 'monastry', ',', 'relinguish', 'claims', 'wood-cuting', 'fishery', 'rihgts', '.', 'He', 'ready', 'becuase', 'rights', 'become', 'much', 'less', 'valuable', ',', 'indeed', 'vaguest', 'idea', 'wood', 'river', 'question', '.']\n",
            "['He', 'determine', 'drop', 'litigation', 'monastry', ',', 'relinguish', 'claim', 'wood-cuting', 'fishery', 'rihgts', '.', 'He', 'ready', 'becuase', 'right', 'become', 'much', 'le', 'valuable', ',', 'indeed', 'vague', 'idea', 'wood', 'river', 'question', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlOKkwYkUpLV"
      },
      "source": [
        "### **Note:-** \n",
        "Lemmatization is done on the basis of part-of-speech tagging (POS tagging).\n",
        "\n",
        "Here, **v** stands for **verb**, **a** stands for **adjective** and **n** stands for **noun**. The lemmatizer only lemmatizes those words which match the pos parameter of the lemmatize method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0V1JtyIZ5_j"
      },
      "source": [
        "## **Text Normalization using Spacy.**\n",
        "\n",
        "Note:- There is no module for Stemming in Spacy. we can only perform lemmatization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ihr5jA9tafd3"
      },
      "source": [
        "### **Lemmatization.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fe2Va4GUOpD"
      },
      "source": [
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZADXugdaqTY"
      },
      "source": [
        "doc = nlp(u\"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \n",
        "fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \n",
        "indeed the vaguest idea where the wood and river in question were.\"\"\")\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1_kpFdUazrv",
        "outputId": "89af396a-657a-4cd6-b9f9-522fe345171a"
      },
      "source": [
        "# Lemmatization.\n",
        "lemma_words = []\n",
        "for tokens in doc:\n",
        "  lemma_words.append(tokens.lemma_)\n",
        "\n",
        "print(lemma_words)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['-PRON-', 'determine', 'to', 'drop', '-PRON-', 'litigation', 'with', 'the', 'monastry', ',', 'and', 'relinguish', '-PRON-', 'claim', 'to', 'the', 'wood', '-', 'cut', 'and', '\\n', 'fishery', 'rihgts', 'at', 'once', '.', '-PRON-', 'be', 'the', 'more', 'ready', 'to', 'do', 'this', 'becuase', 'the', 'right', 'have', 'become', 'much', 'less', 'valuable', ',', 'and', '-PRON-', 'have', '\\n', 'indeed', 'the', 'vague', 'idea', 'where', 'the', 'wood', 'and', 'river', 'in', 'question', 'be', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdrkmzlybM_U"
      },
      "source": [
        "### **Note:-**\n",
        "Here -PRON- is the notation for pronoun which could easily be removed using regular expressions. The benefit of spaCy is that we do not have to pass any pos parameter to perform lemmatization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vBcb9DzbW64"
      },
      "source": [
        "## **Text Normalization using TextBlob.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2TWa28zbgi6"
      },
      "source": [
        "### Note:- \n",
        "Similar to Spacy, TextBlob has no module for stemming."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLslrAHsbw1Q"
      },
      "source": [
        "### **Lemmatization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrbEpgJ8bGQG",
        "outputId": "54b9f347-e0f2-43f6-a9db-25ed8bde22fa"
      },
      "source": [
        "from textblob import Word\n",
        "\n",
        "text = \"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \n",
        "fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \n",
        "indeed the vaguest idea where the wood and river in question were.\"\"\"\n",
        "\n",
        "lem = []\n",
        "for i in text.split():\n",
        "  word1 = Word(i).lemmatize(\"n\")\n",
        "  word2 = Word(word1).lemmatize(\"v\")\n",
        "  word3 = Word(word2).lemmatize(\"a\")\n",
        "  lem.append(Word(word3).lemmatize())\n",
        "print(lem)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['He', 'determine', 'to', 'drop', 'his', 'litigation', 'with', 'the', 'monastry,', 'and', 'relinguish', 'his', 'claim', 'to', 'the', 'wood-cuting', 'and', 'fishery', 'rihgts', 'at', 'once.', 'He', 'wa', 'the', 'more', 'ready', 'to', 'do', 'this', 'becuase', 'the', 'right', 'have', 'become', 'much', 'le', 'valuable,', 'and', 'he', 'have', 'indeed', 'the', 'vague', 'idea', 'where', 'the', 'wood', 'and', 'river', 'in', 'question', 'were.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3ObTLKKcZyT"
      },
      "source": [
        "> TextBlob also uses POS tagging to perform lemmatization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8DjAhS_chdY"
      },
      "source": [
        "### That's It !!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XquzyJp_cjxv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}