{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Removing_Stopwords.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO4fmnrqBVEjcv1x17+VYKA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raj-dot-GitHub/NLP-Notes/blob/main/Stopwords/NLP_Removing_Stopwords.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyCITTX0QKZc"
      },
      "source": [
        "### In this notebook we will learn about stopwords and how to remove them from our text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9PXeB75Rjt9"
      },
      "source": [
        "## **What are Stopwords?**\n",
        "> Stopwords are the most common words in any natural language. For the purpose of analyzing text data and building NLP models, these stopwords might not add much value to the meaning of the document.\n",
        "\n",
        "Generally, the most common words used in a text are “the”, “is”, “in”, “for”, “where”, “when”, “to”, “at” etc.\n",
        "\n",
        "Eg. \"There is a pen on the table.\"\n",
        "\n",
        "So, in the above example the words \"is\", \"a\", \"on\" and \"the\" add no meaning to the statement while parsing it. Whereas the keywords of the statement are \"there\", \"book\", \"table\". "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp08IOr_TK7k"
      },
      "source": [
        "### **Note:-** We perform tokenization before removing stopwords."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwJbvl2yTboo"
      },
      "source": [
        "## **Why do we need to remove \"Stopwords\"?**\n",
        "> Removing stopwords is not a hard and fast rule in NLP. It depends upon the task that we are working on. For tasks like text classification, where the text is to be classified into different categories, stopwords are removed or excluded from the given text so that more focus can be given to those words which define the meaning of the text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa5j6bSJT_jb"
      },
      "source": [
        "## **Advantages of removing Stopwords**.\n",
        "\n",
        "1. On removing stopwords, dataset size decreases and the time to train the model also decreases.\n",
        "2. Removing stopwords can potentially help improve the performance as there are fewer and only meaningful tokens left. Thus, it could increase classification accuracy.\n",
        "3. Even search engines like Google remove stopwords for fast and relevant retrieval of data from the database "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w49HwyFUfHV"
      },
      "source": [
        "## **When should we remove stopwords?**\n",
        "\n",
        "I’ve summarized this into two parts: when we can remove stopwords and when we should avoid doing so.\n",
        "\n",
        "### **Remove Stopwords**\n",
        "\n",
        "We can remove stopwords while performing tasks:-\n",
        "\n",
        "*   Text Classification\n",
        "    *   Spam Filtering\n",
        "    *   Language Classification\n",
        "    *   Genre Classification\n",
        "\n",
        "* Caption Generation\n",
        "* Auto-Tag Generation\n",
        "\n",
        "### **Avoid Stopword removal**\n",
        "\n",
        "* Machine Translation\n",
        "* Language Modeling\n",
        "* Text Summarization\n",
        "* Question-Answering problems\n",
        "\n",
        "Any many more...\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBPMYydoW4GR"
      },
      "source": [
        "## **Different NLP libaries which we will use to remove stopwords are:**\n",
        "\n",
        "1. NLTK\n",
        "2. Spacy\n",
        "3. Gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc3fKxVspFLx"
      },
      "source": [
        "## **Stopwords removal using NLTK**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGpwZ3IAQCHR",
        "outputId": "c6404cb7-d02e-488e-bf68-345eb128fe8e"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "print(set(stopwords.words(\"english\")))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "{'out', 'my', \"needn't\", 'now', 'or', 'this', 'these', 'was', 'd', 'wouldn', 'y', 'all', 'myself', 'we', 'after', 'has', 'both', 'until', 'for', 'ain', 'yours', 'before', 'but', 'there', 'are', 'up', 'of', \"hasn't\", 'their', 'then', \"couldn't\", 'isn', 'than', 'and', 'here', 'mustn', 'with', 'been', \"aren't\", \"it's\", 'were', 'you', 'yourself', 'few', 'needn', 'be', 'above', 'he', 'is', 'each', 'below', 'more', 's', 've', 'am', 'if', 'haven', 'ma', 'through', 'those', 'won', 'it', 'i', 'our', 'll', 'such', 'very', 'at', \"shouldn't\", 'over', 'm', \"you've\", 'how', \"should've\", 'only', 'nor', \"you'd\", 'does', 'your', 'she', 'into', 'most', \"that'll\", 'yourselves', 'can', 'when', 'themselves', 'weren', 'mightn', 'against', 'no', 'not', \"weren't\", 'hadn', 'herself', 'himself', 'had', 're', 'its', \"wouldn't\", 'didn', 'have', 'about', \"won't\", 'own', 'in', 'during', 'doesn', 'again', 'having', \"hadn't\", 'shouldn', 'who', 'why', 'them', 'aren', \"shan't\", 'should', 'just', \"mustn't\", 'her', 'they', 'ourselves', 'any', 'too', 'under', 'whom', \"wasn't\", \"haven't\", 'theirs', 'him', 'off', 'o', 'couldn', 'me', 't', 'down', \"isn't\", 'same', 'ours', 'which', 'where', 'shan', 'do', 'itself', 'doing', \"mightn't\", 'an', 'wasn', 'hers', 'being', \"don't\", 'further', \"you're\", 'other', 'while', 'to', 'did', 'from', 'that', 'once', \"she's\", 'by', \"doesn't\", \"you'll\", 'some', 'between', \"didn't\", 'his', 'a', 'don', 'so', 'hasn', 'will', 'because', 'on', 'as', 'what', 'the'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKEZP_bpXhtX",
        "outputId": "e96c2069-0caf-4047-f7e2-cf3c95a96525"
      },
      "source": [
        "# Count of English stopwords in NLTK.\n",
        "len(set(stopwords.words(\"english\")))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2Y-ll8YX0aA"
      },
      "source": [
        "text = \"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \n",
        "fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \n",
        "indeed the vaguest idea where the wood and river in question were.\"\"\"\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "# Tokenization\n",
        "word_token = word_tokenize(text)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si_Y-53kZTwl",
        "outputId": "302a9ad4-bb91-407d-91a6-81ca82de82b3"
      },
      "source": [
        "filtered_sentence = []\n",
        "for word in word_token:\n",
        "  if word not in stop_words:\n",
        "    filtered_sentence.append(word)\n",
        "\n",
        "print(\"\\n\\nOriginal text\\n\\n\")\n",
        "print(\" \".join(word_token))\n",
        "\n",
        "print(\"\\n\\nFiltered Sentence \\n\\n\")\n",
        "print(\" \".join(filtered_sentence)) \n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Original text\n",
            "\n",
            "\n",
            "He determined to drop his litigation with the monastry , and relinguish his claims to the wood-cuting and fishery rihgts at once . He was the more ready to do this becuase the rights had become much less valuable , and he had indeed the vaguest idea where the wood and river in question were .\n",
            "\n",
            "\n",
            "Filtered Sentence \n",
            "\n",
            "\n",
            "He determined drop litigation monastry , relinguish claims wood-cuting fishery rihgts . He ready becuase rights become much less valuable , indeed vaguest idea wood river question .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t827oQxeaXga",
        "outputId": "ca047ed8-aaaa-47a0-dad2-c54a45dbf904"
      },
      "source": [
        "print(\"Length of Original text {}\".format(len(word_token)))\n",
        "print(\"Length of Filtered text {}\".format(len(filtered_sentence)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Original text 56\n",
            "Length of Filtered text 26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRWBqPkVhrlR"
      },
      "source": [
        "## **Stopwords removal using Spacy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB3IO5yDjcfT",
        "outputId": "e6a22128-72ac-463d-a8f5-3a38fb762fb1"
      },
      "source": [
        "from spacy.lang.en import English\n",
        "\n",
        "# Load English tokenizer, tagger, parser, NER and word vectors\n",
        "nlp = English()\n",
        "# Default stopwords in Spacy\n",
        "print(nlp.Defaults.stop_words)\n",
        "print(\"There are {} default stopwords in Spacy.\".format(len(nlp.Defaults.stop_words)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'somewhere', 'beforehand', 'this', 'within', 'therefore', 'becomes', 'toward', \"'ll\", 'has', 'since', 'ever', 'until', 'keep', 'for', 'latterly', 'yours', 'twelve', 'n’t', 'there', '‘ll', 'afterwards', 'up', 'of', 'moreover', 'give', 'serious', 'bottom', 'always', 'above', 'empty', 'is', 'each', 'everywhere', 'quite', 'less', 'anyone', 'it', 'such', 'towards', 'over', 'thru', 'nor', 'into', 'most', 'neither', 'various', 'otherwise', 'thereupon', 'when', 'former', 'themselves', 'besides', 'herself', 'its', 'hereby', 'amount', 'own', 'made', 'who', 'eight', 'should', 'her', 'due', 'name', 'too', 'elsewhere', 'back', 'whom', 'beyond', 'done', 'eleven', 'indeed', 'everything', 'ours', 'side', 'do', 'doing', 'seeming', 'one', '‘d', 'did', 'make', 'anything', 'nine', 'some', 'along', 'whereby', 'see', 'others', 'everyone', 'per', 'out', 'someone', 'none', '‘s', 'three', 'wherein', 'two', 'really', 'could', 'least', 'show', 'than', 'six', 'you', 'also', 'few', 'be', 'often', 'he', 'nevertheless', 'more', 'below', 'call', 'am', 'through', 'those', 'already', 'only', 'fifteen', 'your', 'nowhere', 'become', 'whoever', 'not', 'sometime', 'twenty', 'had', 'first', 'thereafter', 'together', 'in', 'during', '‘re', 'however', 'whereas', 'using', 'mostly', 'ca', 'thereby', 'under', '’d', 'take', 'anyhow', 'nothing', 'same', 'which', 'many', 'itself', 'an', 'further', 'sixty', 'throughout', 'several', 'while', 'by', 'between', 'either', 'whatever', 'as', 'must', 'put', 'anyway', 'please', '’re', 'whither', 'front', 'never', 'my', 'now', 'these', 'yet', 'myself', 'after', 'hereupon', 'whole', 'wherever', 'before', 'are', 'their', 'and', 'been', 'top', 'across', 'yourself', 'whereafter', '‘m', 'if', 'last', 'around', 'amongst', 'whether', 'our', 'became', 'meanwhile', 'at', 'enough', 'hence', 'whenever', 'she', 'much', 'ten', 'move', 'five', 'might', 'full', 'get', 'against', 'no', 'something', 'regarding', 'rather', 'seem', 'well', 'onto', 'just', 'though', 'upon', 'via', 'off', 'seems', 'down', 'go', 'behind', 'almost', 'whose', 'from', 'that', 'whereupon', 'still', 'a', 'his', 'next', 'hundred', 'thus', '’ll', '’s', 'will', 'sometimes', 'say', 'four', 'third', 'cannot', 'even', 'anywhere', 'or', 'was', 'except', 'herein', 'all', 'formerly', 'we', 'both', 'thence', 'but', 'therein', 'then', 'without', 'here', 'noone', 'with', 'mine', '‘ve', 'were', 'somehow', 'else', 'whence', 'forty', 'i', 'very', 'seemed', 'how', \"'s\", \"'ve\", 'although', 'does', 'n‘t', \"'m\", 'yourselves', 'can', \"n't\", '’m', '’ve', 'himself', 're', 'fifty', 'have', 'about', 'alone', 'again', 'nobody', 'part', 'why', 'hereafter', 'them', 'beside', 'would', 'unless', 'namely', 'they', \"'re\", 'ourselves', 'any', 'among', 'him', 'me', 'becoming', 'where', 'hers', 'being', 'us', 'other', 'may', 'another', 'to', 'latter', 'once', 'so', 'used', 'because', 'on', 'perhaps', 'every', 'what', \"'d\", 'the'}\n",
            "There are 326 default stopwords in Spacy.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y7HPXURbDzR",
        "outputId": "565848a9-88f9-425d-d68c-2ab039d75ebc"
      },
      "source": [
        "text = \"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \n",
        "fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \n",
        "indeed the vaguest idea where the wood and river in question were.\"\"\"\n",
        "\n",
        "#  \"nlp\" Object is used to create documents with linguistic annotations.\n",
        "my_doc = nlp(text)\n",
        "\n",
        "# Create list of word tokens\n",
        "token_list = []\n",
        "for token in my_doc:\n",
        "    token_list.append(token.text)\n",
        "\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "# Create list of word tokens after removing stopwords\n",
        "filtered_sentence =[] \n",
        "\n",
        "for word in token_list:\n",
        "    lexeme = nlp.vocab[word]\n",
        "    if lexeme.is_stop == False:\n",
        "        filtered_sentence.append(word) \n",
        "print(token_list)\n",
        "print(filtered_sentence)   "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['He', 'determined', 'to', 'drop', 'his', 'litigation', 'with', 'the', 'monastry', ',', 'and', 'relinguish', 'his', 'claims', 'to', 'the', 'wood', '-', 'cuting', 'and', '\\n', 'fishery', 'rihgts', 'at', 'once', '.', 'He', 'was', 'the', 'more', 'ready', 'to', 'do', 'this', 'becuase', 'the', 'rights', 'had', 'become', 'much', 'less', 'valuable', ',', 'and', 'he', 'had', '\\n', 'indeed', 'the', 'vaguest', 'idea', 'where', 'the', 'wood', 'and', 'river', 'in', 'question', 'were', '.']\n",
            "['determined', 'drop', 'litigation', 'monastry', ',', 'relinguish', 'claims', 'wood', '-', 'cuting', '\\n', 'fishery', 'rihgts', '.', 'ready', 'becuase', 'rights', 'valuable', ',', '\\n', 'vaguest', 'idea', 'wood', 'river', 'question', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efHffo2DiOcC",
        "outputId": "4e0403b7-14ac-49d4-805b-63f8bd423a76"
      },
      "source": [
        "print(len(token_list))\n",
        "print(len(filtered_sentence))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60\n",
            "26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrwYC_EvihKZ",
        "outputId": "459c3944-613d-4f59-a03e-915e4e67bb35"
      },
      "source": [
        "# To check if a word is a stopword or not.\n",
        "nlp.vocab[\"myself\"].is_stop"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHXgN-ksku16"
      },
      "source": [
        "# 'myself' is a stopword which is also included in the stopword list."
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l98XIEGHk5iL",
        "outputId": "3ba18d73-81e3-4c8c-9184-22a339e49b6d"
      },
      "source": [
        "nlp.vocab[\"mystery\"].is_stop"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTapHngyk-1_"
      },
      "source": [
        "# Add any word to the stopword list.\n",
        "nlp.Defaults.stop_words.add(\"mystery\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ToEgZ0Wlxho"
      },
      "source": [
        "# Set the stop_word tag on the lexeme\n",
        "nlp.vocab['mystery'].is_stop = True"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCqbZ2GrlRmo",
        "outputId": "90ca13df-d655-4336-c331-897da0f38f5b"
      },
      "source": [
        "len(nlp.Defaults.stop_words)  # It has changed from 326 to 327."
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "327"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXiEb_JJlVC4",
        "outputId": "2f95b613-0990-40fa-b5e7-b898d5930dad"
      },
      "source": [
        "# Let's check if 'mystery' is really added to the stopwords list.\n",
        "nlp.vocab[\"mystery\"].is_stop"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b9zcMOzloPu"
      },
      "source": [
        "# Remove any word from the default stopwords list.\n",
        "nlp.Defaults.stop_words.remove(\"beyond\")\n",
        "\n",
        "# Remove the stop_word tag from the lexeme\n",
        "nlp.vocab['beyond'].is_stop = False"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUs226wLmGff",
        "outputId": "9f30e1b2-65a8-408e-f3d0-a193fa4f0722"
      },
      "source": [
        "nlp.vocab['beyond'].is_stop"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJBMbfWImbFM"
      },
      "source": [
        "## **Stopwords removal using Gensim**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuVC67YpmoWE"
      },
      "source": [
        "We can use gensim's  remove_stopwords method from the class gensim.parsing.preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-VDwtBsmI9c"
      },
      "source": [
        "from gensim.parsing.preprocessing import remove_stopwords\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7yKkK3Km6Ks",
        "outputId": "78299f2e-a1f0-4249-98e3-28d3a15e06e5"
      },
      "source": [
        "result = remove_stopwords(\"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, \n",
        "and he had indeed the vaguest idea where the wood and river in question were.\"\"\")\n",
        "\n",
        "print('\\n\\n Filtered Sentence \\n\\n')\n",
        "print(result)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " Filtered Sentence \n",
            "\n",
            "\n",
            "He determined drop litigation monastry, relinguish claims wood-cuting fishery rihgts once. He ready becuase rights valuable, vaguest idea wood river question were.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMNPi8d2m9MW",
        "outputId": "5d86c136-e14b-441b-8252-e6b36d8398e1"
      },
      "source": [
        "print(len(result))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QVq5Q6TnjBT"
      },
      "source": [
        "**Note:-** While using gensim for removing stopwords, we can directly use it on the raw text. There’s no need to perform tokenization before removing stopwords. This can save us a lot of time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG6opQQyoBV0"
      },
      "source": [
        "## **That's It !**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy0mPSy7ncr4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}