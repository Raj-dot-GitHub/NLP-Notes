{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Tokenization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNo3+tavI6qAwS/AbNx3H/6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raj-dot-GitHub/NLP-Notes/blob/main/Tokenization/NLP_Tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4CAhykHEXys"
      },
      "source": [
        "#### In this notebook we will discover two types of tokenization techniques and their implementation in different NLP libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bmb7-FzUUJ3j"
      },
      "source": [
        "## **What is Tokenization?**\n",
        "\n",
        "> Tokenization is essentially splitting a phrase, sentence, paragraph, or an entire text document into smaller units, such as individual words or terms. Each of these smaller units are called **tokens**. These tokens could be words, numbers or punctuation marks.\n",
        "\n",
        "Let’s take an example. Consider the below string:\n",
        "\n",
        "“This is a cat.”\n",
        "\n",
        "Output after tokenization:- [\"This\", \"is\", \"a\", \"cat\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNiOs9ZmFv5I"
      },
      "source": [
        "## **Why do we need Tokenization?**\n",
        "> Tokenization will divide the text into words. This will make it easier to interpret the text by analysing the words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQw6NYwvu2Vq"
      },
      "source": [
        "### **1. Tokenization using Python's split() function:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCtSH0WvvHeU"
      },
      "source": [
        "#### **Word Tokenization** :- Dividing the text into a list of words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAg3IbItvgQr",
        "outputId": "d6d99532-f9fa-4981-be1a-34b2f8315164"
      },
      "source": [
        "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \n",
        "species by building a self-sustaining city on Mars. In 2008, SpaceX’s Falcon 1 became the first privately developed \n",
        "liquid-fuel launch vehicle to orbit the Earth.\"\"\"\n",
        "\n",
        "text.split()     # This will split words from whitespace."
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Founded',\n",
              " 'in',\n",
              " '2002,',\n",
              " 'SpaceX’s',\n",
              " 'mission',\n",
              " 'is',\n",
              " 'to',\n",
              " 'enable',\n",
              " 'humans',\n",
              " 'to',\n",
              " 'become',\n",
              " 'a',\n",
              " 'spacefaring',\n",
              " 'civilization',\n",
              " 'and',\n",
              " 'a',\n",
              " 'multi-planet',\n",
              " 'species',\n",
              " 'by',\n",
              " 'building',\n",
              " 'a',\n",
              " 'self-sustaining',\n",
              " 'city',\n",
              " 'on',\n",
              " 'Mars.',\n",
              " 'In',\n",
              " '2008,',\n",
              " 'SpaceX’s',\n",
              " 'Falcon',\n",
              " '1',\n",
              " 'became',\n",
              " 'the',\n",
              " 'first',\n",
              " 'privately',\n",
              " 'developed',\n",
              " 'liquid-fuel',\n",
              " 'launch',\n",
              " 'vehicle',\n",
              " 'to',\n",
              " 'orbit',\n",
              " 'the',\n",
              " 'Earth.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00eS0mLawEMy"
      },
      "source": [
        "#### **Sentence Tokenization :-** Dividing the text into a list of sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe_jZSJ0weur",
        "outputId": "d7d45ce1-9a18-42d4-ee6d-2c4746662964"
      },
      "source": [
        "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \n",
        "species by building a self-sustaining city on Mars. In 2008, SpaceX’s Falcon 1 became the first privately developed \n",
        "liquid-fuel launch vehicle to orbit the Earth.\"\"\"\n",
        "\n",
        "text.split(\". \")   # This will split from wherever a sentence terminates."
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \\nspecies by building a self-sustaining city on Mars',\n",
              " 'In 2008, SpaceX’s Falcon 1 became the first privately developed \\nliquid-fuel launch vehicle to orbit the Earth.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRRBXdfexINI"
      },
      "source": [
        "#### **Drawbacks of using Python's split() method for tokenization:**\n",
        "\n",
        "1.  We can use only one separator at a time.\n",
        "2.  In Word Tokenization, split() did not consider punctuation as a separate token. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl6a4Iavz0vV"
      },
      "source": [
        "### **2. Tokenization using Regular Expressions (RegEx):**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXLENonE0rKQ"
      },
      "source": [
        "#### **Word Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9Mki5iYUAml",
        "outputId": "22f22b11-93ce-4517-93f4-d9217085e21a"
      },
      "source": [
        "import re\n",
        "text = \"Hello, I\\'m Raj Sinha, a statistic graduate and a machine learning enthusiast !\"\n",
        "words = re.split(r\"\\W+\", text)   # Splitting by Whitespace\n",
        "print(words)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Hello', 'I', 'm', 'Raj', 'Sinha', 'a', 'statistic', 'graduate', 'and', 'a', 'machine', 'learning', 'enthusiast', '']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDKJODj26csG",
        "outputId": "8273ad62-9bf1-4ba6-e0a2-da0cd3abd334"
      },
      "source": [
        "# Removing punctuations from the text.\n",
        "\n",
        "text = 'I\\'m with you for the entire life in U.K.!'\n",
        "import string\n",
        "import re\n",
        "# split into words by white space\n",
        "words = text.split()\n",
        "# prepare regex for char filtering\n",
        "re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
        "# remove punctuation from each word\n",
        "stripped = [re_punc.sub('', w) for w in words]\n",
        "print(stripped)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Im', 'with', 'you', 'for', 'the', 'entire', 'life', 'in', 'UK']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUmWSn8fSNMF",
        "outputId": "26b29f75-36bb-4481-e892-a58563addb43"
      },
      "source": [
        "# We can use \"string.printable\" which is opposite of \"string.punctuation\" to return to the original text.\n",
        "\n",
        "re_print = re.compile(r\"[^%s]\" % re.escape(string.printable))\n",
        "result = [re_print.sub(\"\", w) for w in words]\n",
        "print(result)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Hello,', \"I'm\", 'Raj', 'Sinha,', 'a', 'statistic', 'graduate', 'and', 'a', 'machine', 'learning', 'enthusiast', '!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwop0D2L1GXl"
      },
      "source": [
        "#### **Sentence Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDkswYxS1NxY",
        "outputId": "de0c1d22-09b9-4f5f-c8eb-52e97c63178c"
      },
      "source": [
        "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \n",
        "species by building a self-sustaining city on, Mars. In 2008, SpaceX’s Falcon 1 became the first privately developed \n",
        "liquid-fuel launch vehicle to orbit the Earth.\"\"\"\n",
        "\n",
        "sentences = re.compile(\"[.!?]\").split(text)\n",
        "print(sentences)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \\nspecies by building a self-sustaining city on, Mars', ' In 2008, SpaceX’s Falcon 1 became the first privately developed \\nliquid-fuel launch vehicle to orbit the Earth', '']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L_eKsL-18qz"
      },
      "source": [
        "#### **Note:-** We used re.compile() function wherein we passed [.?!] as the seperators. Using this method gives us an edge over the Python's split() method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNAin2Mk29O9"
      },
      "source": [
        "### **3. Tokenization in NLTK**\n",
        "\n",
        "NLTK provides us with a tokenize() module which further classifies in two sub-categories:\n",
        "1. word_tokenize  (Word tokenization)\n",
        "2. sent_tokenize  (Sentence tokenization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0Hn26L73HQw"
      },
      "source": [
        "#### **Word Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0E0upuk3OuC",
        "outputId": "42dd74d3-b7e7-4f48-c146-dd75e13e5c42"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')        # You have to download 'punkt' module from nltk."
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqBrArrP3TPJ",
        "outputId": "ac17eb76-f934-4d75-cb9f-1681ee13da64"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \n",
        "species by building a self-sustaining city on, Mars. In 2008, SpaceX’s Falcon 1 became the first privately developed \n",
        "liquid-fuel launch vehicle to orbit the Earth.\"\"\"\n",
        "\n",
        "tokenized = word_tokenize(text)\n",
        "print(tokenized)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Founded', 'in', '2002', ',', 'SpaceX', '’', 's', 'mission', 'is', 'to', 'enable', 'humans', 'to', 'become', 'a', 'spacefaring', 'civilization', 'and', 'a', 'multi-planet', 'species', 'by', 'building', 'a', 'self-sustaining', 'city', 'on', ',', 'Mars', '.', 'In', '2008', ',', 'SpaceX', '’', 's', 'Falcon', '1', 'became', 'the', 'first', 'privately', 'developed', 'liquid-fuel', 'launch', 'vehicle', 'to', 'orbit', 'the', 'Earth', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viKgGXAg4iwA"
      },
      "source": [
        "#### **Sentence Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJV_O30Z4pr1",
        "outputId": "d2ff0118-712c-4ff2-f76e-f2672b780d48"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "text = \"\"\"A.P.J. Abdul Kalam, in full Avul Pakir Jainulabdeen Abdul Kalam, (born October 15, 1931, Rameswaram, India—died July 27, 2015, Shillong), Indian scientist and politician who played a leading role in the development of India’s missile and nuclear weapons programs. He was president of India from 2002 to 2007.\"\"\"\n",
        "\n",
        "tokenized = sent_tokenize(text)\n",
        "print(tokenized)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A.P.J.', 'Abdul Kalam, in full Avul Pakir Jainulabdeen Abdul Kalam, (born October 15, 1931, Rameswaram, India—died July 27, 2015, Shillong), Indian scientist and politician who played a leading role in the development of India’s missile and nuclear weapons programs.', 'He was president of India from 2002 to 2007.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBbh1uAp5cn7"
      },
      "source": [
        "#### **Note:-** NLTK is considering punctuation as a token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWYL5IQ1UT68",
        "outputId": "71e70c2a-5645-48d9-ce85-cc4dfe3fe2e3"
      },
      "source": [
        "# Lowering the words in the text:\n",
        "\n",
        "words = text.split()\n",
        "# Convert to lower case\n",
        "lower_words = [word.lower() for word in words]\n",
        "print(lower_words)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['hello,', \"i'm\", 'raj', 'sinha,', 'a', 'statistic', 'graduate', 'and', 'a', 'machine', 'learning', 'enthusiast', '!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RT9W1fObMOT"
      },
      "source": [
        "### **4. Tokenization using Spacy.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTOQwWnQ8Ro_"
      },
      "source": [
        "#### **Word Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adMWmj_nbUW_"
      },
      "source": [
        "# We will use spacy.lang.en which supports English language.\n",
        "from spacy.lang.en import English\n",
        "\n",
        "# Load English tokenizer, tagger, parser, NER and word vectors\n",
        "nlp = English()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW2omlL3bhFN"
      },
      "source": [
        "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \n",
        "species by building a self-sustaining city on Mars. In 2008, SpaceX’s Falcon 1 became the first privately developed \n",
        "liquid-fuel launch vehicle to orbit the Earth\"\"\""
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oERRF_Pbuyn",
        "outputId": "57b8c6a5-71cf-4a95-d41d-09b3fe2e33c3"
      },
      "source": [
        "# Create a word list containing tokens of the text.\n",
        "doc = nlp(text)\n",
        "tokens_list = []\n",
        "for tokens in doc:\n",
        "  tokens_list.append(tokens.text)\n",
        "\n",
        "print(tokens_list)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Founded', 'in', '2002', ',', 'SpaceX', '’s', 'mission', 'is', 'to', 'enable', 'humans', 'to', 'become', 'a', 'spacefaring', 'civilization', 'and', 'a', 'multi', '-', 'planet', '\\n', 'species', 'by', 'building', 'a', 'self', '-', 'sustaining', 'city', 'on', 'Mars', '.', 'In', '2008', ',', 'SpaceX', '’s', 'Falcon', '1', 'became', 'the', 'first', 'privately', 'developed', '\\n', 'liquid', '-', 'fuel', 'launch', 'vehicle', 'to', 'orbit', 'the', 'Earth']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DGfbxaGcFDM",
        "outputId": "49ac80f2-ea8d-4bab-9565-ae61ff1f1d32"
      },
      "source": [
        "# Looping through the tokens in the text.\n",
        "doc2 = nlp(u\"We're here to help! Join our Discord server, named as Datazen and also don't forget to follow us on Instagram.\")\n",
        "for tokens in doc2:\n",
        "  print(tokens)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We\n",
            "'re\n",
            "here\n",
            "to\n",
            "help\n",
            "!\n",
            "Join\n",
            "our\n",
            "Discord\n",
            "server\n",
            ",\n",
            "named\n",
            "as\n",
            "Datazen\n",
            "and\n",
            "also\n",
            "do\n",
            "n't\n",
            "forget\n",
            "to\n",
            "follow\n",
            "us\n",
            "on\n",
            "Instagram\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R5rGjagcuB_",
        "outputId": "b5c0e056-a66c-4686-9a20-5e8ca320b081"
      },
      "source": [
        "doc3 = nlp(u\"I\\'m 6 feet tall and my BMI is 22.31, which suggests that I\\'m healthy. So I decided to order a cheese pizza for myself worth $5.\")\n",
        "for tokens in doc3:\n",
        "  print(tokens)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I\n",
            "'m\n",
            "6\n",
            "feet\n",
            "tall\n",
            "and\n",
            "my\n",
            "BMI\n",
            "is\n",
            "22.31\n",
            ",\n",
            "which\n",
            "suggests\n",
            "that\n",
            "I\n",
            "'m\n",
            "healthy\n",
            ".\n",
            "So\n",
            "I\n",
            "decided\n",
            "to\n",
            "order\n",
            "a\n",
            "cheese\n",
            "pizza\n",
            "for\n",
            "myself\n",
            "worth\n",
            "$\n",
            "5\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5IckS1EdlDg",
        "outputId": "c367b7f3-6bf5-4d98-874e-e01ef6bac024"
      },
      "source": [
        "doc4 = nlp(u\"Let's visit St. Louis in the U.S. next year.\")\n",
        "for tokens in doc4:\n",
        "  print(tokens)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let\n",
            "'s\n",
            "visit\n",
            "St.\n",
            "Louis\n",
            "in\n",
            "the\n",
            "U.S.\n",
            "next\n",
            "year\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiLBIIV9d8vi",
        "outputId": "827553f8-0e78-4fb9-988f-7bc67b18075f"
      },
      "source": [
        "len(doc4)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzyZ0BMAeAxm",
        "outputId": "f85596bf-5546-4673-a7c8-89282a63136c"
      },
      "source": [
        "len(doc)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpIYtpjIeGUv",
        "outputId": "c5a96dec-bf87-45ed-8c10-7e010d34ec15"
      },
      "source": [
        "len(doc3.vocab)      # Count of vocabulary in doc3 variable."
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "528"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbuTAEWueKL1",
        "outputId": "02553216-c710-4165-af49-a263b6dd1af3"
      },
      "source": [
        "# Indexing:\n",
        "doc5 = nlp(u'It is better to give than to receive')\n",
        "print(doc5[2])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "better\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKtbcA3Keja2",
        "outputId": "429fd673-2599-4d50-80d5-128aa42f1ffb"
      },
      "source": [
        "# Slicing:\n",
        "print(doc5[1:4])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "is better to\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ53z7h0exzC",
        "outputId": "edc48cf0-01bf-43fd-cafb-30409d26ed81"
      },
      "source": [
        "print(doc5[-4:])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "give than to receive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7xAqDBMe6XL",
        "outputId": "94e21dbc-f940-4fab-8a4f-6a85be3eb47f"
      },
      "source": [
        "doc6 = nlp(u'Apple to build a factory in Hong Kong for $6 million')\n",
        "for tokens in doc6:\n",
        "  print(tokens.text, end = \",\")\n",
        "\n",
        "print(\"\\n\\n-----------------------\")\n",
        "\n",
        "# Tokens associated with their labels.\n",
        "for ent in doc6.ents:\n",
        "  print(ent.text + \" - \" + ent.label_ + str(spacy.explain(ent.label_)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple,to,build,a,factory,in,Hong,Kong,for,$,6,million,\n",
            "\n",
            "-----------------------\n",
            "Apple - ORGCompanies, agencies, institutions, etc.\n",
            "Hong Kong - GPECountries, cities, states\n",
            "$6 million - MONEYMonetary values, including unit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ET1BN9W4gF2Z",
        "outputId": "521861a0-fc47-475e-ca7f-b4c2139a209e"
      },
      "source": [
        "print(doc6.ents)\n",
        "print(len(doc6.ents))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Apple, Hong Kong, $6 million)\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EXA6wYOgNxU",
        "outputId": "aa1f0cc2-5b32-4845-ef59-9744e4cd0c89"
      },
      "source": [
        "# Dividing the text into chunks.\n",
        "doc7 = nlp(u\"Autonomous cars shift insurance liability toward manufacturers.\")\n",
        "for chunks in doc7.noun_chunks:     # Noun chunks\n",
        "  print(chunks.text)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Autonomous cars\n",
            "insurance liability\n",
            "manufacturers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGtjZqDRhAAV",
        "outputId": "83b5190e-c1eb-4306-fe16-fb91c2277d9e"
      },
      "source": [
        "doc8 = nlp(u\"Red cars do not carry higher insurance rates.\")\n",
        "for chunks in doc8.noun_chunks:\n",
        "  print(chunks.text)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Red cars\n",
            "higher insurance rates\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcGkRNcWhe1l",
        "outputId": "cdc8bb02-c987-45e2-ebef-50298afc853c"
      },
      "source": [
        "doc9 = nlp(u\"He was a one-eyed, one-horned, flying, purple people-eater.\")\n",
        "for chunks in doc9.noun_chunks:\n",
        "  print(chunks.text)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "He\n",
            "a one-eyed, one-horned, flying, purple people-eater\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "ZPeBb_Rqhwu0",
        "outputId": "cc65a83e-e840-438b-e1c0-caa42979124a"
      },
      "source": [
        "# Using 'displacy' to find the parts of speech of the tokens in the text with visuals:\n",
        "from spacy import displacy\n",
        "doc10 = nlp(u\"Apple is going to build a factory in U.K. for $6 million.\")\n",
        "displacy.render(doc10, style = 'dep', jupyter = True, options = {'distance': 110})"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c227693d41594ff9aef446cf4da99efe-0\" class=\"displacy\" width=\"1480\" height=\"357.0\" direction=\"ltr\" style=\"max-width: none; height: 357.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">going</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">build</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">factory</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">U.K.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">for</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">$</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">SYM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1260\">6</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1260\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1370\">million.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1370\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c227693d41594ff9aef446cf4da99efe-0-0\" stroke-width=\"2px\" d=\"M70,222.0 C70,112.0 260.0,112.0 260.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c227693d41594ff9aef446cf4da99efe-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,224.0 L62,212.0 78,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c227693d41594ff9aef446cf4da99efe-0-1\" stroke-width=\"2px\" d=\"M180,222.0 C180,167.0 255.0,167.0 255.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c227693d41594ff9aef446cf4da99efe-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M180,224.0 L172,212.0 188,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c227693d41594ff9aef446cf4da99efe-0-2\" stroke-width=\"2px\" d=\"M400,222.0 C400,167.0 475.0,167.0 475.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c227693d41594ff9aef446cf4da99efe-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M400,224.0 L392,212.0 408,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c227693d41594ff9aef446cf4da99efe-0-3\" stroke-width=\"2px\" d=\"M290,222.0 C290,112.0 480.0,112.0 480.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c227693d41594ff9aef446cf4da99efe-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M480.0,224.0 L488.0,212.0 472.0,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c227693d41594ff9aef446cf4da99efe-0-4\" stroke-width=\"2px\" d=\"M620,222.0 C620,167.0 695.0,167.0 695.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c227693d41594ff9aef446cf4da99efe-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M620,224.0 L612,212.0 628,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c227693d41594ff9aef446cf4da99efe-0-5\" stroke-width=\"2px\" d=\"M510,222.0 C510,112.0 700.0,112.0 700.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c227693d41594ff9aef446cf4da99efe-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M700.0,224.0 L708.0,212.0 692.0,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c227693d41594ff9aef446cf4da99efe-0-6\" stroke-width=\"2px\" d=\"M730,222.0 C730,167.0 805.0,167.0 805.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c227693d41594ff9aef446cf4da99efe-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M805.0,224.0 L813.0,212.0 797.0,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c227693d41594ff9aef446cf4da99efe-0-7\" stroke-width=\"2px\" d=\"M840,222.0 C840,167.0 915.0,167.0 915.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c227693d41594ff9aef446cf4da99efe-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M915.0,224.0 L923.0,212.0 907.0,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c227693d41594ff9aef446cf4da99efe-0-8\" stroke-width=\"2px\" d=\"M510,222.0 C510,2.0 1040.0,2.0 1040.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c227693d41594ff9aef446cf4da99efe-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1040.0,224.0 L1048.0,212.0 1032.0,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c227693d41594ff9aef446cf4da99efe-0-9\" stroke-width=\"2px\" d=\"M1170,222.0 C1170,112.0 1360.0,112.0 1360.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c227693d41594ff9aef446cf4da99efe-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1170,224.0 L1162,212.0 1178,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c227693d41594ff9aef446cf4da99efe-0-10\" stroke-width=\"2px\" d=\"M1280,222.0 C1280,167.0 1355.0,167.0 1355.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c227693d41594ff9aef446cf4da99efe-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1280,224.0 L1272,212.0 1288,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c227693d41594ff9aef446cf4da99efe-0-11\" stroke-width=\"2px\" d=\"M1060,222.0 C1060,57.0 1365.0,57.0 1365.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c227693d41594ff9aef446cf4da99efe-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1365.0,224.0 L1373.0,212.0 1357.0,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "61Dq8rCrinF4",
        "outputId": "8c2114ed-6166-45d6-b438-bf08c37ac0da"
      },
      "source": [
        "# Using 'displacy' to get description about the tokens.\n",
        "doc11 = nlp(u\"Over the last quarter Apple sold nearly 20 thousand iPods for a profit of $6 million.\")\n",
        "displacy.render(doc11, style = 'ent', jupyter= True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the last quarter\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Apple\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " sold \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    nearly 20 thousand\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    iPods\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
              "</mark>\n",
              " for a profit of \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    $6 million\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              ".</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eh7NU-oAjFVE",
        "outputId": "0c146ec1-e442-4807-8ce5-142afab3b922"
      },
      "source": [
        "doc12 = nlp(u\"This is a sentence.\")\n",
        "displacy.serve(doc12, style = 'dep')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using the 'dep' visualizer\n",
            "Serving on http://0.0.0.0:5000 ...\n",
            "\n",
            "Shutting down server on port 5000.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErEuwFS0-Bo9"
      },
      "source": [
        "### **Sentence Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwkbvxS3jdcT"
      },
      "source": [
        "from spacy.lang.en import English\n",
        "\n",
        "nlp = English()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLoJjQJ2-TgK",
        "outputId": "5a96998d-ee70-4e82-85a5-34f5df970c6a"
      },
      "source": [
        "# Creating the pipeline \"sentencizer\" component\n",
        "sbd = nlp.create_pipe('sentencizer')\n",
        "\n",
        "# Add the component to the pipeline\n",
        "nlp.add_pipe(sbd)\n",
        "\n",
        "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \n",
        "species by building a self-sustaining city on Mars. In 2008, SpaceX’s Falcon 1 became the first privately developed \n",
        "liquid-fuel launch vehicle to orbit the Earth.\"\"\"\n",
        "\n",
        "#  \"nlp\" Object is used to create documents with linguistic annotations.\n",
        "doc = nlp(text)\n",
        "\n",
        "# create list of sentence tokens\n",
        "sents_list = []\n",
        "for sent in doc.sents:\n",
        "    sents_list.append(sent.text)\n",
        "sents_list"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \\nspecies by building a self-sustaining city on Mars.',\n",
              " 'In 2008, SpaceX’s Falcon 1 became the first privately developed \\nliquid-fuel launch vehicle to orbit the Earth.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuakQUrYAb_x"
      },
      "source": [
        "### **5. Tokenization in Keras**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8x4nqG9-ndv"
      },
      "source": [
        "pip install keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdckFL3iArWg"
      },
      "source": [
        "#### **Word Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAilWV9LAh7C",
        "outputId": "b11134dc-389d-4f0f-a7e3-bf1872d1e419"
      },
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \n",
        "species by building a self-sustaining city on Mars. In 2008, SpaceX’s Falcon 1 became the first privately developed \n",
        "liquid-fuel launch vehicle to orbit the Earth.\"\"\"\n",
        "\n",
        "result = text_to_word_sequence(text)\n",
        "result\n",
        "\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['founded',\n",
              " 'in',\n",
              " '2002',\n",
              " 'spacex’s',\n",
              " 'mission',\n",
              " 'is',\n",
              " 'to',\n",
              " 'enable',\n",
              " 'humans',\n",
              " 'to',\n",
              " 'become',\n",
              " 'a',\n",
              " 'spacefaring',\n",
              " 'civilization',\n",
              " 'and',\n",
              " 'a',\n",
              " 'multi',\n",
              " 'planet',\n",
              " 'species',\n",
              " 'by',\n",
              " 'building',\n",
              " 'a',\n",
              " 'self',\n",
              " 'sustaining',\n",
              " 'city',\n",
              " 'on',\n",
              " 'mars',\n",
              " 'in',\n",
              " '2008',\n",
              " 'spacex’s',\n",
              " 'falcon',\n",
              " '1',\n",
              " 'became',\n",
              " 'the',\n",
              " 'first',\n",
              " 'privately',\n",
              " 'developed',\n",
              " 'liquid',\n",
              " 'fuel',\n",
              " 'launch',\n",
              " 'vehicle',\n",
              " 'to',\n",
              " 'orbit',\n",
              " 'the',\n",
              " 'earth']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSyx052vBPSO"
      },
      "source": [
        "#### **Note:-** Keras lowers the case of all the alphabets before tokenizing them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgKtd0tyBilU"
      },
      "source": [
        "### **6. Tokenization using Gensim**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpHCp_ckBIAI",
        "outputId": "b1c65679-3d67-4f26-c97b-2e4e1986e8b2"
      },
      "source": [
        "pip install gensim"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.1.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JGafNMPB4-q"
      },
      "source": [
        "#### **Word Tokenization**\n",
        "\n",
        "We can use the gensim.utils class to import the tokenize method for performing word tokenization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfSmN8dvBvv0",
        "outputId": "d9748d30-637b-4e43-ccaa-4b12dbf997df"
      },
      "source": [
        "from gensim.utils import tokenize\n",
        "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \n",
        "species by building a self-sustaining city on Mars. In 2008, SpaceX’s Falcon 1 became the first privately developed \n",
        "liquid-fuel launch vehicle to orbit the Earth.\"\"\"\n",
        "list(tokenize(text))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Founded',\n",
              " 'in',\n",
              " 'SpaceX',\n",
              " 's',\n",
              " 'mission',\n",
              " 'is',\n",
              " 'to',\n",
              " 'enable',\n",
              " 'humans',\n",
              " 'to',\n",
              " 'become',\n",
              " 'a',\n",
              " 'spacefaring',\n",
              " 'civilization',\n",
              " 'and',\n",
              " 'a',\n",
              " 'multi',\n",
              " 'planet',\n",
              " 'species',\n",
              " 'by',\n",
              " 'building',\n",
              " 'a',\n",
              " 'self',\n",
              " 'sustaining',\n",
              " 'city',\n",
              " 'on',\n",
              " 'Mars',\n",
              " 'In',\n",
              " 'SpaceX',\n",
              " 's',\n",
              " 'Falcon',\n",
              " 'became',\n",
              " 'the',\n",
              " 'first',\n",
              " 'privately',\n",
              " 'developed',\n",
              " 'liquid',\n",
              " 'fuel',\n",
              " 'launch',\n",
              " 'vehicle',\n",
              " 'to',\n",
              " 'orbit',\n",
              " 'the',\n",
              " 'Earth']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po2XiFSmCeoh"
      },
      "source": [
        "#### **Sentence Tokenization**\n",
        "\n",
        "To perform sentence tokenization, we use the split_sentences method from the gensim.summerization.texttcleaner class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVBHZa1FCSxN",
        "outputId": "1b5de516-96cb-46f5-f005-b11255c9195f"
      },
      "source": [
        "from gensim.summarization.textcleaner import split_sentences\n",
        "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \n",
        "species by building a self-sustaining city on Mars. In 2008, SpaceX’s Falcon 1 became the first privately developed \n",
        "liquid-fuel launch vehicle to orbit the Earth.\"\"\"\n",
        "result = split_sentences(text)\n",
        "result"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet ',\n",
              " 'species by building a self-sustaining city on Mars.',\n",
              " 'In 2008, SpaceX’s Falcon 1 became the first privately developed ',\n",
              " 'liquid-fuel launch vehicle to orbit the Earth.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9glB4vheDEUd"
      },
      "source": [
        "#### **Note:-** Gensim tokenized the text on encountering \"\\n\" while other libraries ignored it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md49RmDiDc4g"
      },
      "source": [
        "## **That's It !!**\n",
        "\n",
        "### Congratulations. You have learned the various tokenization techniques and you have also seen their implementation using different NLP libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbejm8H8C7lc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}